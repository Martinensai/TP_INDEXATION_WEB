# üï∏Ô∏è Web Crawler Project - ENSAI 2026 (TP1)

Ce projet consiste en la cr√©ation d'un crawler web "poli" et optimis√© en Python. L'objectif est d'explorer un site e-commerce, d'extraire des donn√©es structur√©es et de prioriser les pages produits.

## üìÇ Structure du projet

Le code est divis√© en plusieurs modules pour respecter le principe de responsabilit√© unique :

* **`main.py`** : Point d'entr√©e du script. Configure l'URL de d√©part et lance le crawling.
* **`crawling.py`** : G√®re la logique d'exploration, la file d'attente (frontier) et la priorit√© des URLs.
* **`extraction.py`** : Contient les fonctions d'analyse HTML (BeautifulSoup) et la gestion du fichier `robots.txt`.
* **`configuration.py`** : G√®re les requ√™tes HTTP, les headers (User-Agent) et la gestion des erreurs r√©seau.
* **`saving.py`** : G√®re l'exportation des donn√©es au format JSON.
* **`test_crawler.py`** : Tests unitaires pour valider la priorit√© et l'extraction.



## Fonctionnalit√©s impl√©ment√©es

### 1. Politesse et Respect
* **Robots.txt** : Le crawler v√©rifie syst√©matiquement les permissions via `urllib.robotparser` avant de visiter une page.
* **User-Agent** : Identification personnalis√©e (`ENSAI-Crawler-2026`).
* **D√©lai (Politeness delay)** : Une pause de 1 seconde est marqu√©e entre chaque requ√™te pour ne pas surcharger le serveur.

### 2. Strat√©gie d'exploration
* **Priorisation** : Les URLs contenant le mot-cl√© `product` sont plac√©es en t√™te de file pour √™tre trait√©es en priorit√©.
* **Limite de volume** : Le crawler s'arr√™te automatiquement apr√®s avoir visit√© 50 pages uniques.
* **Gestion des doublons** : Utilisation d'un ensemble (`set`) pour garantir qu'aucune page n'est visit√©e deux fois.

### 3. Extraction des donn√©es
Pour chaque page valide, le crawler extrait :
* Le titre de la page.
* L'URL compl√®te.
* Le premier paragraphe (`<p>`) du contenu.
* La liste des liens internes pr√©sents dans le corps (`<body>`) de la page.

## Utilisation

### Pr√©requis
* Python 3.x
* Biblioth√®que BeautifulSoup4 : `pip install beautifulsoup4`

### Lancement
Ex√©cutez simplement le script principal :
```bash
python main.py